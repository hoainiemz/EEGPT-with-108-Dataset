[34m[1mwandb[0m: Detected [huggingface_hub.inference] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
502 119 131
752
LitEEGPTCausal(
  (target_encoder): EEGTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(1, 512, kernel_size=(1, 64), stride=(1, 64))
    )
    (chan_embed): Embedding(62, 512)
    (blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  )
  (chan_conv): Conv1dWithConstraint(19, 19, kernel_size=(1,), stride=(1,))
  (linear_probe1): LinearWithConstraint(in_features=2048, out_features=16, bias=True)
  (linear_probe2): LinearWithConstraint(in_features=1872, out_features=1, bias=True)
  (drop): Dropout(p=0.5, inplace=False)
  (arranger): Rearrange('b 1 -> (b 1)')
)
  0%|                                                                                                              | 0/63 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/EEGPT/finetune_kfold_pearl.py", line 105, in <module>
    main()
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/EEGPT/finetune_kfold_pearl.py", line 80, in main
    acc_, pr_auc_, roc_auc_ = t.train_for_binaryclass()
                              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/EEGPT/finetune_trainer_kfold.py", line 85, in train_for_binaryclass
    pred = self.model(x)
           ^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiemeegpt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/EEGPT/downstream/model_for_pearls.py", line 91, in mono_forward
    z = self.target_encoder(x, self.chans_id.to(x))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiemeegpt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/EEGPT/downstream/Modules/models/EEGPT_mcae.py", line 767, in forward
    x = blk(x) # B*N, mC+1, D
        ^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiemeegpt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/EEGPT/downstream/Modules/models/EEGPT_mcae.py", line 283, in forward
    y = self.attn(self.norm1(x), freqs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiemeegpt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/EEGPT/downstream/Modules/models/EEGPT_mcae.py", line 263, in forward
    x = self.proj(x)
        ^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiemeegpt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiemeegpt/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.50 GiB total capacity; 3.91 GiB already allocated; 2.62 MiB free; 4.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
