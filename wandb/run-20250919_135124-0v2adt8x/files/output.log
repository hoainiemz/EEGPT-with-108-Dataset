[34m[1mwandb[0m: Detected [huggingface_hub.inference] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
502 119 131
752
LitEEGPTCausal(
  (target_encoder): EEGTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(1, 512, kernel_size=(1, 64), stride=(1, 64))
    )
    (chan_embed): Embedding(62, 512)
    (blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  )
  (chan_conv): Conv1dWithConstraint(19, 19, kernel_size=(1,), stride=(1,))
  (linear_probe1): LinearWithConstraint(in_features=2048, out_features=16, bias=True)
  (linear_probe2): LinearWithConstraint(in_features=1872, out_features=1, bias=True)
  (drop): Dropout(p=0.5, inplace=False)
  (arranger): Rearrange('b 1 -> (b 1)')
)
 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                        | 56/502 [00:12<01:36,  4.64it/s]
Traceback (most recent call last):
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/EEGPT/finetune_kfold_pearl.py", line 105, in <module>
    main()
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/EEGPT/finetune_kfold_pearl.py", line 80, in main
    acc_, pr_auc_, roc_auc_ = t.train_for_binaryclass()
                              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/EEGPT/finetune_trainer_kfold.py", line 92, in train_for_binaryclass
    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.params.clip_value)
  File "/mnt/disk1/aiotlab/envs/hoainiemeegpt/lib/python3.11/site-packages/torch/nn/utils/clip_grad.py", line 76, in clip_grad_norm_
    torch._foreach_mul_(grads, clip_coef_clamped.to(device))  # type: ignore[call-overload]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
