503 112 137
752
LitEEGPTCausal(
  (target_encoder): EEGTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(1, 128, kernel_size=(1, 64), stride=(1, 64))
    )
    (chan_embed): Embedding(62, 128)
    (blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=128, out_features=384, bias=True)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
  )
  (chan_conv): Conv1dWithConstraint(19, 19, kernel_size=(1,), stride=(1,))
  (meta_backbone): Sequential(
    (0): Linear(in_features=28, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=128, out_features=128, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.1, inplace=False)
  )
  (arranger): Rearrange('b c s d -> b (c s) d')
  (attention): ParamAttention(
    (Wq): Linear(in_features=128, out_features=128, bias=False)
    (Wk): Linear(in_features=128, out_features=128, bias=False)
    (Wv): Linear(in_features=128, out_features=128, bias=False)
    (drop): Dropout(p=0.1, inplace=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=128, out_features=1, bias=True)
    (1): Rearrange('b 1 -> (b 1)')
  )
  (backbone): Sequential(
    (0): Conv1dWithConstraint(19, 19, kernel_size=(1,), stride=(1,))
    (1): EEGTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(1, 128, kernel_size=(1, 64), stride=(1, 64))
      )
      (chan_embed): Embedding(62, 128)
      (blocks): ModuleList(
        (0-7): 8 x Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    )
  )
)
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.75it/s]
Epoch 1 : Training Loss: 0.67438, LR: 0.00030, Time elapsed 0.07 mins
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 12.10it/s]
val Evaluation: acc: 0.38393, pr_auc: 0.33799, roc_auc: 0.17857
[[43 13]
 [56  0]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.38393, pr_auc: 0.33799, roc_auc: 0.17857
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.56it/s]
Epoch 2 : Training Loss: 0.51882, LR: 0.00030, Time elapsed 0.07 mins
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 12.30it/s]
val Evaluation: acc: 0.39286, pr_auc: 0.35459, roc_auc: 0.20823
[[35 21]
 [47  9]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.39286, pr_auc: 0.35459, roc_auc: 0.20823
  0%|                                                                                                                  | 0/16 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/EEGPT/finetune_kfold_pearl.py", line 105, in <module>
    main()
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/EEGPT/finetune_kfold_pearl.py", line 80, in main
    acc_, pr_auc_, roc_auc_ = t.train_for_binaryclass()
                              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/EEGPT/finetune_trainer_kfold.py", line 90, in train_for_binaryclass
    losses.append(loss.data.cpu().numpy())
                  ^^^^^^^^^^^^^^^
KeyboardInterrupt
